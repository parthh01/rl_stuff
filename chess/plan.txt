
vaguely remember watching some geohot stream where he sets up a bit-wise representation of chess for RL bot as well I think, 
making my own here i'm sure (I hope) it's similar 

EDIT: gave up trying to come up with a good representation myself, will just use his. Not going to use game DB though. 

state representation :- 

    pieces: 
        1x pawns
        1x rooks (x2 castle available)
        1x bishops 
        1x knights 
        1x queen 
        1x king
        1x blank (x2 en passant available)
        ------------
        15 distinct piece-states (white and black )

    so 15 possible inputs representing which pieces are on the board 


    2^1 inputs representing who's turn it is to move 



final state: 

    (15 possible options per square  )* (64 squares)  = 4 bits * 64 squares = 256 bits representing the board 
    2 players (white or black)                                     = 1 bit representing player color 



Reward Function :- 

 +X for a win, -X for a loss, 0 for draw


Objective: 
    create a value network to evaluate state positions using off policy Q learning. 

TODO: 
    convert 1-ply greedy search policy to x-ply minimax with ab pruning 
    for training as well? could use the minimax with 1-epsilon probability 
    








